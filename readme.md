# PrÃ¡ctica Docker: Microservicios con Outbox Pattern

## ğŸ“‹ DescripciÃ³n

Esta prÃ¡ctica implementa el **Outbox Pattern** con microservicios:
- **Producer API (Node.js + Express)**: Recibe requests, guarda eventos en BD y envÃ­a a Kafka
- **Consumer Service**: Lee de Kafka y procesa los mensajes
- **PostgreSQL**: Base de datos compartida
- **Kafka**: Message broker para comunicaciÃ³n asÃ­ncrona

## ğŸ—ï¸ Arquitectura

```
Cliente 
   â†“ POST /messages
Producer API
   â†“ 1. INSERT en tabla 'eventos' (estado: P)
   â†“ 2. Enviar a Kafka
   â†“    â”œâ”€ Ã‰xito â†’ UPDATE estado: E
   â†“    â””â”€ Error â†’ UPDATE estado: X (reintento automÃ¡tico)
   â†“
Kafka (topic: messages)
   â†“
Consumer Service
   â†“ Lee de Kafka
   â†“ INSERT en tabla 'messages'
PostgreSQL
```

### Estados de eventos:
- **P** = Pendiente (aÃºn no enviado a Kafka)
- **E** = Enviado (exitoso a Kafka)
- **X** = Error (fallÃ³, se reintentarÃ¡)

## ğŸš€ InstalaciÃ³n

### Estructura de archivos

```
proyecto/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ producer-api/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ src/
â”‚       â””â”€â”€ index.js
â””â”€â”€ consumer-service/
    â”œâ”€â”€ Dockerfile
    â”œâ”€â”€ package.json
    â””â”€â”€ index.js
```

### Crear la estructura

```bash
# Crear directorios
mkdir -p docker-practice/producer-api/src
mkdir -p docker-practice/consumer-service
cd docker-practice

# Copiar docker-compose.yml en la raÃ­z
# Copiar producer-api/src/index.js
# Copiar consumer-service/index.js
```

### Crear Dockerfiles

**producer-api/Dockerfile**:
```dockerfile
FROM node:18-alpine
WORKDIR /usr/src/app
COPY package*.json ./
RUN npm install
COPY . .
EXPOSE 3000
CMD ["npm", "start"]
```

**consumer-service/Dockerfile** (igual):
```dockerfile
FROM node:18-alpine
WORKDIR /usr/src/app
COPY package*.json ./
RUN npm install
COPY . .
EXPOSE 3001
CMD ["npm", "start"]
```

### Crear package.json para ambos servicios

Usa el mismo `package.json` que ya te proporcionÃ©.

### .dockerignore en ambas carpetas

```
node_modules
npm-debug.log
.git
.gitignore
README.md
.env
.DS_Store
```

### Ejecutar el proyecto

```bash
docker-compose up --build
```

## ğŸ§ª Probar la aplicaciÃ³n

### 1. Verificar servicios
```bash
# Producer API
curl http://localhost:3000/health

# Consumer Service
curl http://localhost:3001/health
```

### 2. Enviar un mensaje
```bash
curl -X POST http://localhost:3000/messages \
  -H "Content-Type: application/json" \
  -d '{"content": "Mi primer evento"}'
```

**Respuesta exitosa:**
```json
{
  "success": true,
  "evento_id": 1,
  "estado": "E",
  "message": "Evento creado y enviado a Kafka exitosamente"
}
```

**Si Kafka falla:**
```json
{
  "success": true,
  "evento_id": 1,
  "estado": "X",
  "message": "Evento creado pero fallÃ³ el envÃ­o a Kafka. Se reintentarÃ¡ automÃ¡ticamente."
}
```

### 3. Ver eventos con su estado
```bash
curl http://localhost:3000/eventos
```

VerÃ¡s algo como:
```json
{
  "count": 3,
  "eventos": [
    {
      "id": 1,
      "content": "Mi primer evento",
      "estado": "Enviado",
      "intentos": 0,
      "created_at": "2025-01-15T10:30:00.000Z"
    },
    {
      "id": 2,
      "content": "Evento con error",
      "estado": "Error",
      "intentos": 3,
      "error_message": "Connection timeout",
      "created_at": "2025-01-15T10:31:00.000Z"
    }
  ]
}
```

### 4. Ver mensajes procesados
```bash
curl http://localhost:3000/messages
```

### 5. Ver estadÃ­sticas
```bash
# Producer API stats
curl http://localhost:3000/stats

# Consumer Service stats
curl http://localhost:3001/stats
```

## ğŸ” Probar el sistema de reintentos

### Simular fallo de Kafka

```bash
# 1. Detener Kafka temporalmente
docker-compose stop kafka

# 2. Enviar un mensaje (se marcarÃ¡ como 'X')
curl -X POST http://localhost:3000/messages \
  -H "Content-Type: application/json" \
  -d '{"content": "Este fallarÃ¡"}'

# 3. Ver que estÃ¡ en estado X
curl http://localhost:3000/eventos

# 4. Reiniciar Kafka
docker-compose start kafka

# 5. Esperar 10 segundos (reintento automÃ¡tico)
# 6. Ver que ahora estÃ¡ en estado E
curl http://localhost:3000/eventos
```

## ğŸ“Š Comandos Ãºtiles

### Ver logs
```bash
# Producer API
docker-compose logs -f producer-api

# Consumer Service
docker-compose logs -f consumer-service

# Kafka
docker-compose logs -f kafka
```

### Verificar BD
```bash
docker exec -it postgres_db psql -U admin -d myapp

# Ver eventos
SELECT id, content, procesado, intentos, created_at FROM eventos ORDER BY id DESC LIMIT 10;

# Ver mensajes procesados
SELECT m.id, m.content, m.evento_id, m.created_at 
FROM messages m 
ORDER BY m.id DESC LIMIT 10;

# EstadÃ­sticas
SELECT 
  procesado,
  COUNT(*) as cantidad,
  CASE 
    WHEN procesado = 'P' THEN 'Pendiente'
    WHEN procesado = 'E' THEN 'Enviado'
    WHEN procesado = 'X' THEN 'Error'
  END as descripcion
FROM eventos 
GROUP BY procesado;
```

### Verificar Kafka
```bash
# Ver mensajes en el topic
docker exec -it kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic messages \
  --from-beginning

# Ver consumer groups
docker exec -it kafka kafka-consumer-groups \
  --bootstrap-server localhost:9092 \
  --list

# Ver lag del consumer
docker exec -it kafka kafka-consumer-groups \
  --bootstrap-server localhost:9092 \
  --group message-processor-group \
  --describe
```

## ğŸ¯ Ventajas del Outbox Pattern

### âœ… Ventajas:
1. **GarantÃ­a de entrega**: El evento se guarda en BD antes de enviarse
2. **Reintentos automÃ¡ticos**: Si Kafka falla, se reintenta periÃ³dicamente
3. **AuditorÃ­a completa**: Sabes exactamente quÃ© se enviÃ³ y cuÃ¡ndo
4. **Resiliencia**: Si Kafka estÃ¡ caÃ­do, la API sigue funcionando
5. **Idempotencia**: Puedes reprocesar eventos sin duplicados
6. **Desacoplamiento**: Producer y Consumer son independientes

### âš ï¸ Consideraciones:
1. MÃ¡s complejidad que envÃ­o directo
2. Requiere job de limpieza de eventos antiguos
3. Necesita mÃ¡s espacio en BD

## ğŸ”¥ Escenarios de prueba

### Prueba 1: Flujo normal
```bash
# Enviar 5 mensajes
for i in {1..5}; do
  curl -X POST http://localhost:3000/messages \
    -H "Content-Type: application/json" \
    -d "{\"content\": \"Mensaje $i\"}"
  sleep 1
done

# Verificar todos llegaron
curl http://localhost:3000/stats
curl http://localhost:3001/stats
```

### Prueba 2: Alta carga
```bash
# Enviar 100 mensajes simultÃ¡neos
for i in {1..100}; do
  curl -X POST http://localhost:3000/messages \
    -H "Content-Type: application/json" \
    -d "{\"content\": \"Load test $i\"}" &
done

# Ver el LAG en Kafka
docker exec -it kafka kafka-consumer-groups \
  --bootstrap-server localhost:9092 \
  --group message-processor-group \
  --describe
```

### Prueba 3: RecuperaciÃ³n de fallos
```bash
# 1. Detener consumer
docker-compose stop consumer-service

# 2. Enviar mensajes
for i in {1..10}; do
  curl -X POST http://localhost:3000/messages \
    -H "Content-Type: application/json" \
    -d "{\"content\": \"Queued message $i\"}"
done

# 3. Ver que estÃ¡n en Kafka pero no procesados
curl http://localhost:3000/messages  # VacÃ­o o sin los Ãºltimos 10

# 4. Reiniciar consumer
docker-compose start consumer-service

# 5. Verificar que se procesaron todos
sleep 5
curl http://localhost:3000/messages
```

## ğŸ“š Conceptos aplicados

- âœ… **Outbox Pattern**: Eventos en BD antes de Kafka
- âœ… **Event Sourcing**: Historial completo de eventos
- âœ… **Microservicios**: Producer y Consumer independientes
- âœ… **Idempotencia**: Reintentos seguros
- âœ… **Circuit Breaker**: Manejo de fallos de Kafka
- âœ… **At-least-once delivery**: GarantÃ­a de entrega

## ğŸ“ Ejercicios propuestos

1. Agregar un job que limpie eventos enviados hace mÃ¡s de 30 dÃ­as
2. Implementar Dead Letter Queue para eventos que fallan 3+ veces
3. Agregar mÃ©tricas con Prometheus
4. Crear un dashboard con Grafana
5. Implementar mÃºltiples consumers para diferentes tipos de eventos
6. Agregar Redis para cachÃ© de eventos recientes
7. Implementar particionamiento de Kafka por tipo de evento

## ğŸ› Troubleshooting

Ver la secciÃ³n de troubleshooting del README anterior, mÃ¡s:

### Eventos quedan en estado X
```bash
# Ver eventos con error
curl http://localhost:3000/eventos | jq '.eventos[] | select(.estado == "Error")'

# Verificar logs del producer
docker-compose logs producer-api | grep "Error"

# Forzar reprocesamiento (reiniciar producer)
docker-compose restart producer-api
```

## ğŸ”— Referencias

- [Outbox Pattern](https://microservices.io/patterns/data/transactional-outbox.html)
- [Event Sourcing](https://martinfowler.com/eaaDev/EventSourcing.html)
- [Kafka Documentation](https://kafka.apache.org/documentation/)
- [Saga Pattern](https://microservices.io/patterns/data/saga.html)

```bash
docker-compose down -v
docker-compose up --build
```